# -*- coding: utf-8 -*-
"""Copy of Dicoding ML-Image Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iFO5_zsHuWd0J2qMIJUzIS2t_cPvf-jk
"""

!pip install -q kaggle

from google.colab import files
files.upload()

# membuat directory dan mengubah izin file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d tongpython/cat-and-dog

# unzip
!mkdir cat-and-dog
!unzip cat-and-dog.zip -d cat-and-dog
!ls cat-and-dog

"""Library"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D, Dense, GlobalAveragePooling2D, Dropout, Flatten
import matplotlib.pyplot as plt
import pathlib

"""Load Dataset"""

train_ds = '/content/cat-and-dog/training_set/training_set'
test_ds = '/content/cat-and-dog/test_set/test_set'

"""Preprocessing"""

train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=40,
                                   width_shift_range=0.1,
                                   height_shift_range=0.1,
                                   shear_range=0.1,
                                   zoom_range=0.1,
                                   horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_ds,target_size=(150, 150),
    batch_size=64,
    shuffle=True,
    class_mode='binary',
)


test_generator = test_datagen.flow_from_directory(
    test_ds,target_size=(150,150),
    batch_size=64,
    shuffle=False,
    class_mode='binary',
)

train_generator[0][0].shape

"""Modeling"""

def create_model():
  model = Sequential([
      Conv2D(96, (11, 11), activation='relu', input_shape=(150, 150, 3)),
      MaxPooling2D(3, 3),
      Conv2D(256, (5,5), activation='relu'),
      MaxPooling2D(3,3),
      Conv2D(384, (3,3), activation='relu'),
      Conv2D(256, (3,3), activation='relu'),
      Conv2D(256, (3,3), activation='relu'),
      MaxPooling2D(3,3),

      Flatten(),
      Dense(4096, activation= 'relu'),
      Dropout(0.5),
      Dense(4096, activation= 'relu'),
      Dropout(0.5),
      Dense(1, activation = 'sigmoid')
  ])

  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),
                loss='binary_crossentropy',
                metrics=['accuracy'])

  return model

model = create_model()
model.summary()

#callback
reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.15,
    patience=5,
    min_lr=2.e-5
)

stop_early = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0,
    patience=10,
    verbose=0,
    mode="auto",
    baseline=None,
    restore_best_weights=True
)

history = model.fit(train_generator,
                    validation_data = test_generator,
                    epochs = 50,
                    verbose = 1,
                    callbacks = [reduce_LR, stop_early])

"""Plot Loss dan Akurasi"""

plt.figure(figsize=(15,6))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['Training loss', 'Validation loss'])
plt.show()

plt.figure(figsize=(15,6))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['Training accuracy','Validation accuracy'])
plt.show()

"""Convert Model"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('vegs.tflite')
tflite_model_file.write_bytes(tflite_model)